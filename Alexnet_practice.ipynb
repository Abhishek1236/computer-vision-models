{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet_practice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPed0gFAlQe8gUjk1J44dmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek1236/computer-vision-models/blob/main/Alexnet_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xowVGIa68DSw",
        "outputId": "dceeb2f0-0022-4cbd-c38f-e859dd425fea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#importing the libraries\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\r\n",
        " Conv2D, MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "import numpy as np\r\n",
        "import tflearn.datasets.oxflower17 as oxflower17\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "np.random.seed(1000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXijRQhVoF-N"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1zWKuOQpE1A",
        "outputId": "962052b7-4723-4ee8-d558-0f0d7e68d841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/3c/0b156d08ef3d4e2a8009ecab2af1ad2e304f6fb99562b6271c68a74a4397/tflearn-0.5.0.tar.gz (107kB)\n",
            "\r\u001b[K     |███                             | 10kB 30.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 34.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40kB 24.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61kB 25.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81kB 18.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102kB 17.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 17.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (7.0.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-cp36-none-any.whl size=127301 sha256=1bb5816b024ce5c71ef3e5c0d623ff3c7112ed221a5a00c4e60cc615f546ce83\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d2/ed/fb9a0d301dd9586c11e9547120278e624227f22fd5f4baf744\n",
            "Successfully built tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0p1K8dV8Mi_",
        "outputId": "959351f4-fba7-43ca-c7bf-d67d7a7ca5a6"
      },
      "source": [
        "#preparing the data \r\n",
        "x, y = oxflower17.load_data(one_hot=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Succesfully downloaded 17flowers.tgz 60270631 bytes.\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlTY6R0O8lqU"
      },
      "source": [
        "#Model \r\n",
        "class Alexnet:\r\n",
        "  def __init__(self,batch_size,epoch,validation_split,x,y):\r\n",
        "    self.batch_size = batch_size\r\n",
        "    self.epoch = epoch\r\n",
        "    self.validation_split = validation_split\r\n",
        "    self.x = x\r\n",
        "    self.y = y\r\n",
        "  def forward():\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(96,input_shape=(224,224,3),kernel_size=(11,11),strides=(4,4),padding='valid'))# first conv\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Conv2D(256,kernel_size=(5,5),padding='same'))# second conv\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),strides=(1,1)))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Conv2D(384,kernel_size=(3,3),padding=\"same\",strides=(1,1)))#third conv\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),padding='valid'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Conv2D(256,kernel_size=(3,3),padding='valid'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(4096))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(Dense(4096))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(Dense(17))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    return model\r\n",
        "  def training(x,y,batch_size,epochs,validation_split,model):\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\r\n",
        "    model.fit(x,y, batch_size=batch_size, epochs=epochs, verbose=1,validation_split=validation_split, shuffle=True)\r\n",
        "    return model\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fzBLAzQCO07",
        "outputId": "af020c0a-9f10-48bf-eb6b-238a62570711"
      },
      "source": [
        "\r\n",
        "#printing the summary of the model\r\n",
        "model = Alexnet.forward()\r\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 54, 54, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 96)        384       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 384)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              4198400   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 17)                69649     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 17)                0         \n",
            "=================================================================\n",
            "Total params: 23,473,041\n",
            "Trainable params: 23,471,057\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4O_tIVaCX9f",
        "outputId": "f927be63-345b-4578-f118-d97156e69574"
      },
      "source": [
        "trained_model = Alexnet.training(x = x,y = y,batch_size=64,epochs= 25,validation_split=0.25,model=model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1020 samples, validate on 340 samples\n",
            "Epoch 1/25\n",
            "1020/1020 [==============================] - ETA: 0s - loss: 4.2207 - acc: 0.2225"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1020/1020 [==============================] - 9s 9ms/sample - loss: 4.2207 - acc: 0.2225 - val_loss: 12.4272 - val_acc: 0.1235\n",
            "Epoch 2/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 1.7120 - acc: 0.4451 - val_loss: 7.0969 - val_acc: 0.1059\n",
            "Epoch 3/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 1.2733 - acc: 0.5716 - val_loss: 3.7422 - val_acc: 0.2412\n",
            "Epoch 4/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.9942 - acc: 0.6627 - val_loss: 2.7566 - val_acc: 0.3412\n",
            "Epoch 5/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.7605 - acc: 0.7353 - val_loss: 3.5593 - val_acc: 0.2765\n",
            "Epoch 6/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.5869 - acc: 0.8078 - val_loss: 2.7182 - val_acc: 0.3853\n",
            "Epoch 7/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.5007 - acc: 0.8275 - val_loss: 2.4803 - val_acc: 0.4059\n",
            "Epoch 8/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.4482 - acc: 0.8490 - val_loss: 4.9444 - val_acc: 0.2824\n",
            "Epoch 9/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.4018 - acc: 0.8569 - val_loss: 3.2061 - val_acc: 0.4265\n",
            "Epoch 10/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.3218 - acc: 0.8931 - val_loss: 3.4817 - val_acc: 0.3735\n",
            "Epoch 11/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2915 - acc: 0.9010 - val_loss: 3.6301 - val_acc: 0.4118\n",
            "Epoch 12/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2528 - acc: 0.9206 - val_loss: 2.5208 - val_acc: 0.4882\n",
            "Epoch 13/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2595 - acc: 0.9098 - val_loss: 2.2027 - val_acc: 0.5676\n",
            "Epoch 14/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.1889 - acc: 0.9333 - val_loss: 4.7013 - val_acc: 0.4382\n",
            "Epoch 15/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.1825 - acc: 0.9451 - val_loss: 2.9063 - val_acc: 0.5647\n",
            "Epoch 16/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.1665 - acc: 0.9412 - val_loss: 2.5457 - val_acc: 0.6088\n",
            "Epoch 17/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2209 - acc: 0.9353 - val_loss: 3.1592 - val_acc: 0.4971\n",
            "Epoch 18/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2201 - acc: 0.9225 - val_loss: 4.5971 - val_acc: 0.4176\n",
            "Epoch 19/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.1193 - acc: 0.9608 - val_loss: 3.8572 - val_acc: 0.5147\n",
            "Epoch 20/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.0510 - acc: 0.9892 - val_loss: 3.2285 - val_acc: 0.5647\n",
            "Epoch 21/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.0527 - acc: 0.9853 - val_loss: 2.7396 - val_acc: 0.6412\n",
            "Epoch 22/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.0403 - acc: 0.9804 - val_loss: 2.5469 - val_acc: 0.6353\n",
            "Epoch 23/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.1087 - acc: 0.9667 - val_loss: 2.3286 - val_acc: 0.6441\n",
            "Epoch 24/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2432 - acc: 0.9294 - val_loss: 3.3300 - val_acc: 0.5441\n",
            "Epoch 25/25\n",
            "1020/1020 [==============================] - 1s 1ms/sample - loss: 0.2594 - acc: 0.9304 - val_loss: 6.2222 - val_acc: 0.3882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3oPfsTvG7lN"
      },
      "source": [
        "#saving to disk\r\n",
        "trained_model.save('Alexnet.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSkmTpYWHoIr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}