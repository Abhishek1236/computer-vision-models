{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/dogs-vs-cats/test1.zip\n/kaggle/input/dogs-vs-cats/train.zip\n/kaggle/input/dogs-vs-cats/sampleSubmission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture cell_output\n\n# unzipping train.zip \n!unzip \"../input/dogs-vs-cats/train.zip\"\n\n#rename train folder\nimport os\n\nsrc_train = os.path.join(os.getcwd(), 'src_train')\n\nos.rename(os.path.join(os.getcwd(), 'train'), src_train)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture cell_output\n\n# unzipping test1.zip \n!unzip \"../input/dogs-vs-cats/test1.zip\"\n\ntest_dir = os.path.join(os.getcwd(), 'test1')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = os.path.join(os.getcwd(), \"train\")\nif not os.path.isdir(train_dir):\n    os.mkdir(train_dir)\n\ntrain_cats = os.path.join(train_dir, \"cats\")\nif not os.path.isdir(train_cats):\n    os.mkdir(train_cats)\n\ntrain_dogs = os.path.join(train_dir, \"dogs\")\nif not os.path.isdir(train_dogs):\n    os.mkdir(train_dogs)\n\n#validation folders   \nvalidation_dir = os.path.join(os.getcwd(), \"validation\")\nif not os.path.isdir(validation_dir):\n    os.mkdir(validation_dir)\n\n    \nval_cats = os.path.join(validation_dir, \"cats\")\nif not os.path.isdir(val_cats):\n    os.mkdir(val_cats)\n\nval_dogs = os.path.join(validation_dir, \"dogs\")\nif not os.path.isdir(val_dogs):\n    os.mkdir(val_dogs)\n\n#hold_out folder\nhold_out = os.path.join(os.getcwd(), \"hold_out\")\nif not os.path.isdir(hold_out):\n    os.mkdir(hold_out)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport random\nsrc_trn_files = os.listdir(src_train)\n\n#list of file names with cat images from train dir\ncat_files = [src_trn_files[i] for i, x in enumerate(src_trn_files) if re.match(r'^cat', x)]\n\n#list of file names with dog images from train dir\ndog_files = [src_trn_files[i] for i, x in enumerate(src_trn_files) if re.match(r'^dog', x)]\n\n#random sample 2100 cats image file names\ncat_files = random.sample(cat_files, 2100)\n\n#random sample 2100 dogs image file names\ndog_files = random.sample(dog_files, 2100)\n\nimport shutil\n\n#copy cats images to train_cats folder\nfor fname in cat_files[:1500]:\n    src = os.path.join(src_train, fname)\n    dst = os.path.join(train_cats, fname)\n    shutil.copyfile(src, dst)\n    \n#copy cats images to val_cats folder\nfor fname in cat_files[1500:2000]:\n    src = os.path.join(src_train, fname)\n    dst = os.path.join(val_cats, fname)\n    shutil.copyfile(src, dst)\n\n#copy dog images to train_dogs folder\nfor fname in dog_files[:1500]:\n    src = os.path.join(src_train, fname)\n    dst = os.path.join(train_dogs, fname)\n    shutil.copyfile(src, dst)\n\n#copy dogs images to val_dogs folder\nfor fname in dog_files[1500:2000]:\n    src = os.path.join(src_train, fname)\n    dst = os.path.join(val_dogs, fname)\n    shutil.copyfile(src, dst)\n    \n#copy dogs & cats images to hold_out folder\nfor fname in cat_files[2000:] + dog_files[2000:] :\n    src = os.path.join(src_train, fname)\n    dst = os.path.join(hold_out, fname)\n    shutil.copyfile(src, dst)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\n\nval_datagen = ImageDataGenerator(rescale=1./255)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(train_dir,\n                                                    target_size=(150,150),\n                                                    batch_size=20,\n                                                    class_mode='binary')\n\nvalidation_generator = val_datagen.flow_from_directory(validation_dir,\n                                                        target_size=(150,150),\n                                                        batch_size=20,\n                                                        class_mode='binary')","execution_count":7,"outputs":[{"output_type":"stream","text":"Found 3000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the pretrained weights and defining the image size\nIMAGE_SIZE = [150, 150]\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","execution_count":9,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in vgg.layers:\n  layer.trainable = False","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing the final layer for output\nx = Flatten()(vgg.output)\nprediction = Dense(1, activation='sigmoid')(x)\nmodel = Model(inputs=vgg.input, outputs=prediction)\nmodel.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 8193      \n=================================================================\nTotal params: 14,722,881\nTrainable params: 8,193\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\n\n#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\n\n#lr_scheduler = LearningRateScheduler(lr_schedule)\n\n#lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n#                               cooldown=0,\n#                               patience=5,\n#                               min_lr=0.5e-6)\n\n#num_epochs = 1000\n#num_batch_size = 32\n\ncheckpoint = ModelCheckpoint(filepath='mymodel_adam.h5', \n                               verbose=1, save_best_only=True)\n\ncallbacks = [checkpoint]\n\nstart = datetime.now()\n\nmodel.fit_generator(\n  train_generator,\n  validation_data=validation_generator,\n  epochs=15,\n  steps_per_epoch=50,\n  validation_steps=32,\n    callbacks=callbacks ,verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","name":"stderr"},{"output_type":"stream","text":"Epoch 1/15\n50/50 [==============================] - 13s 198ms/step - loss: 0.6521 - accuracy: 0.6063 - val_loss: 0.4049 - val_accuracy: 0.8094\n\nEpoch 00001: val_loss improved from inf to 0.40494, saving model to mymodel_adam.h5\nEpoch 2/15\n50/50 [==============================] - 9s 185ms/step - loss: 0.4712 - accuracy: 0.7657 - val_loss: 0.3822 - val_accuracy: 0.8188\n\nEpoch 00002: val_loss improved from 0.40494 to 0.38217, saving model to mymodel_adam.h5\nEpoch 3/15\n50/50 [==============================] - 10s 194ms/step - loss: 0.4098 - accuracy: 0.8224 - val_loss: 0.3313 - val_accuracy: 0.8422\n\nEpoch 00003: val_loss improved from 0.38217 to 0.33127, saving model to mymodel_adam.h5\nEpoch 4/15\n50/50 [==============================] - 9s 181ms/step - loss: 0.3690 - accuracy: 0.8412 - val_loss: 0.3073 - val_accuracy: 0.8813\n\nEpoch 00004: val_loss improved from 0.33127 to 0.30733, saving model to mymodel_adam.h5\nEpoch 5/15\n50/50 [==============================] - 9s 185ms/step - loss: 0.3936 - accuracy: 0.8186 - val_loss: 0.2845 - val_accuracy: 0.8719\n\nEpoch 00005: val_loss improved from 0.30733 to 0.28451, saving model to mymodel_adam.h5\nEpoch 6/15\n50/50 [==============================] - 9s 187ms/step - loss: 0.3497 - accuracy: 0.8403 - val_loss: 0.3024 - val_accuracy: 0.8656\n\nEpoch 00006: val_loss did not improve from 0.28451\nEpoch 7/15\n50/50 [==============================] - 10s 197ms/step - loss: 0.3514 - accuracy: 0.8351 - val_loss: 0.2816 - val_accuracy: 0.8672\n\nEpoch 00007: val_loss improved from 0.28451 to 0.28162, saving model to mymodel_adam.h5\nEpoch 8/15\n32/50 [==================>...........] - ETA: 2s - loss: 0.3176 - accuracy: 0.8585","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = os.listdir(test_dir)\ntest_df = pd.DataFrame({\n    \"filename\" : test_data\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    test_dir,\n    target_size = (150, 150),\n    x_col = \"filename\",\n    y_col = None,\n    batch_size = 10,\n    class_mode = None,\n    shuffle = True,\n    color_mode=\"rgb\",\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = model.predict(test_generator)\ntest_df['category'] = np.argmax(predicted, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['id'] = test_df['filename'].str.split('.').str[0]\ntest_df['label'] = test_df['category']\ntest_df.drop(['filename', 'category'], axis = 1, inplace = True)\ntest_df.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}